{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Term Frequency?\n",
    "\n",
    "Term Frequency is the number of times that a term appears in a given document. Considering that the value can vary between 0 and a high value, we take it's log, so as to squish it down. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we prefer rare terms over frequent terms?\n",
    "\n",
    "Rare terms are considered to have more information as opposed to frequent terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Inverse Document Frequency(IDF)?\n",
    "\n",
    "IDF is calculated by \n",
    "\n",
    "$$idf_t = \\log({\\frac{N}{df_t}})$$\n",
    "\n",
    "$$ N = \\text{Total number of documents} $$\n",
    "\n",
    "$$ df = \\text{Number of documents which contain the term} $$\n",
    "\n",
    "The intuition behind this is to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we calculate tf-idf?\n",
    "\n",
    "$$ tf\\cdot idf_{t,d} = (1 + \\log{tf_{t,d}}) * \\log{\\frac{N}{df_t}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How are documents represented in Vector-Space?\n",
    "\n",
    "Documents are vectors of $tf \\cdot idf$ for each term. They are denoted by $\\vec{V}(d)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the individual components of a document vector $\\vec{V}(d)$?\n",
    "\n",
    "The individual component of $\\vec{V}(d)$ is a term from the dictionary. They are the axes of the vectors too. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How are queries in vector space?\n",
    " \n",
    "Queries are considered to be documents in the same vector space. That is, each query is converted to a vector using $tf\\cdot idf$. \n",
    "\n",
    "The $tf$ is it's frequency in the given query and $idf$ is calculated using the entire corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For a given query, how are documents ranked? \n",
    "\n",
    "The documents are ranked based on cosine similarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we calculate cosine similarity between a document and a query?\n",
    "\n",
    "$$cos(\\vec{q}, \\vec{d}) = \\frac{\\vec{q}\\cdot\\vec{d}}{||\\vec{q}||_2 ||\\vec{d}||_2 }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the bottleneck for top-k search?\n",
    "\n",
    "The bottleneck is in performing cosine similarity for all the documents in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is inexact topk search?\n",
    "\n",
    "Instead of performing cosine similarity for all the documents in the corpus, we instead find a set of documents $A$, such that $|A| > k$ and $|A| << N$. That is, $A$ is greater than $k$ but much smaller than $N$. \n",
    "\n",
    "We then perform cosine similarity for all the documents in $A$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are champion lists and how are they useful?\n",
    "\n",
    "For a given term, in the dictionary, we keep track of the top $r$ set of documents, based on $idf$. These $r$ documents are called the champion list for the given term $t$. When searching based on a query, we then only search through only the docs in the champion list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is index elimination?\n",
    "\n",
    "Index elimination is when instead of performing a query on all the given terms, we instead perform the search using only half the query terms. These query terms have the higher idf scores.\n",
    "\n",
    "Steps:\n",
    "1. Sort the query terms, in descending order, based on idf values.\n",
    "2. Select top half of the query terms.\n",
    "3. Perform search using the above selected terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the two components in Cluster Pruning, and how are they used?\n",
    "\n",
    "The two components are \n",
    "1. Leaders\n",
    "2. Followers\n",
    "\n",
    "We randomly choose $\\sqrt{N}$ documents to be leaders.\n",
    "\n",
    "For all the remaining documents, we calculate which leader it is closest to and assign it to that leader. This forms a group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How are queries processed when documents are clusted?\n",
    "\n",
    "We first find which leader the query is closest to. Having found this leader, and subsequently the larger group, we then look at all the documents in the group and perform topk search on it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are variants of cluster pruning?\n",
    "\n",
    "Instead of a document belonging to just a leader, we instead attach the document to $b_1$ number of leaders. $b_1 = 3$ is the usual value. \n",
    "\n",
    "Further, instead of looking at just the closest leader, we look for the $b_2$ closest leaders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is an authoritative document?\n",
    "\n",
    "A document is said to be authoritative if it is written by a credible source. \n",
    "\n",
    "Example: \n",
    "\n",
    "A paper on monkeys by a reseracher is authoritative, whereas a comment on reddit by a random person is really not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How is the authority of a document stored?\n",
    "\n",
    "The authority is stored as a quality-score. This is **query independent**. And it is in the range $[0, 1]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For a query are documents ranked, based on authority?\n",
    "\n",
    "Along with using cosine similarity, we score the document using authority. \n",
    "\n",
    "$$score(q, d) = g(d) + cosine(q, d)$$\n",
    "\n",
    "We then return the top k documents, based on the above score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What constitutes meta-data in a document?\n",
    "\n",
    "Meta-data in a document can be considered to be information about the document. \n",
    "\n",
    "Ex:\n",
    "1. Author\n",
    "2. Format\n",
    "3. Data of publication\n",
    "4. Language\n",
    "5. Title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are zones in a document?\n",
    "\n",
    "Zones in a doc can be considered to be regions in a document that have the same semantic connection. \n",
    "\n",
    "Example : \n",
    "1. Title\n",
    "2. Introduction\n",
    "3. Content\n",
    "4. Conclusion\n",
    "5. Footnote"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How are zone-indices encoded?\n",
    "\n",
    "Zone indices are encoded in two ways. \n",
    "\n",
    "1. In posting lists:\n",
    "    - william -> [(2, author), (2, title), ...] This implies that william appears as twice as an author and twice as a title.\n",
    "2. In Dictionaries:\n",
    "    - william.author -> [doc_id]\n",
    "    - william.title -> [doc_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
