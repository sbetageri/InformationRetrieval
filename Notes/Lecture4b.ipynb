{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Term Frequency?\n",
    "\n",
    "Term Frequency is the number of times that a term appears in a given document. Considering that the value can vary between 0 and a high value, we take it's log, so as to squish it down. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why do we prefer rare terms over frequent terms?\n",
    "\n",
    "Rare terms are considered to have more information as opposed to frequent terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Inverse Document Frequency(IDF)?\n",
    "\n",
    "IDF is calculated by \n",
    "\n",
    "$$idf_t = \\log({\\frac{N}{df_t}})$$\n",
    "\n",
    "$$ N = \\text{Total number of documents} $$\n",
    "\n",
    "$$ df = \\text{Number of documents which contain the term} $$\n",
    "\n",
    "The intuition behind this is to "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we calculate tf-idf?\n",
    "\n",
    "$$ tf\\cdot idf_{t,d} = (1 + \\log{tf_{t,d}}) * \\log{\\frac{N}{df_t}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How are documents represented in Vector-Space?\n",
    "\n",
    "Documents are vectors of $tf \\cdot idf$ for each term. They are denoted by $\\vec{V}(d)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the individual components of a document vector $\\vec{V}(d)$?\n",
    "\n",
    "The individual component of $\\vec{V}(d)$ is a term from the dictionary. They are the axes of the vectors too. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How are queries in vector space?\n",
    " \n",
    "Queries are considered to be documents in the same vector space. That is, each query is converted to a vector using $tf\\cdot idf$. \n",
    "\n",
    "The $tf$ is it's frequency in the given query and $idf$ is calculated using the entire corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For a given query, how are documents ranked? \n",
    "\n",
    "The documents are ranked based on cosine similarity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How do we calculate cosine similarity between a document and a query?\n",
    "\n",
    "$$cos(\\vec{q}, \\vec{d}) = \\frac{\\vec{q}\\cdot\\vec{d}}{||\\vec{q}||_2 ||\\vec{d}||_2 }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the bottleneck for top-k search?\n",
    "\n",
    "The bottleneck is in performing cosine similarity for all the documents in the corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is inexact topk search?\n",
    "\n",
    "Instead of performing cosine similarity for all the documents in the corpus, we instead find a set of documents $A$, such that $|A| > k$ and $|A| << N$. That is, $A$ is greater than $k$ but much smaller than $N$. \n",
    "\n",
    "We then perform cosine similarity for all the documents in $A$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are champion lists and how are they useful?\n",
    "\n",
    "For a given term, in the dictionary, we keep track of the top $r$ set of documents, based on $idf$. These $r$ documents are called the champion list for the given term $t$. When searching based on a query, we then only search through only the docs in the champion list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check what is index elimination.!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the two components in Cluster Pruning, and how are they used?\n",
    "\n",
    "The two components are \n",
    "1. Leaders\n",
    "2. Followers\n",
    "\n",
    "We randomly choose $\\sqrt{N}$ documents to be leaders.\n",
    "\n",
    "For all the remaining documents, we calculate which leader it is closest to and assign it to that leader. This forms a group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How are queries processed when documents are clusted?\n",
    "\n",
    "We first find which leader the query is closest to. Having found this leader, and subsequently the larger group, we then look at all the documents in the group and perform topk search on it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are variants of cluster pruning?\n",
    "\n",
    "Instead of a document belonging to just a leader, we instead attach the document to $b_1$ number of leaders. $b_1 = 3$ is the usual value. \n",
    "\n",
    "Further, instead of looking at just the closest leader, we look for the $b_2$ closest leaders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
